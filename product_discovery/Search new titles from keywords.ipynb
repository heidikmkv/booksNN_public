{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get new titles by keyword, MWS\n",
    "Search MWS for keywords in list. \n",
    "Save all ASINs appearing in results, as well as their price, salesrank, and publication date. \n",
    "Then sort lists into interesting and not interesting. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "<frozen importlib._bootstrap>:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "<frozen importlib._bootstrap>:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "<frozen importlib._bootstrap>:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import mws\n",
    "import datetime\n",
    "import time\n",
    "from tenacity import *  \n",
    "\n",
    "import booksnn as bnn\n",
    "\n",
    "#kinda unnecessary so far\n",
    "#from mws_functions import * \n",
    "\n",
    "date = datetime.datetime.now().strftime(\"%Y_%m_%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import list of keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lynx/anaconda3/envs/booksnn/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Afghan & Iraq Wars',\n",
       " 'Aesthetics',\n",
       " 'Aerospace',\n",
       " 'Aeronautics & Astronautics',\n",
       " 'Aerodynamics',\n",
       " 'Aerial',\n",
       " 'Advertising',\n",
       " 'Adventure',\n",
       " 'Advanced Placement',\n",
       " 'Adult Ministry']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load list of keywords\n",
    "keywords = list(pd.read_table('keywords_more_likely_textbooks.txt').columns)\n",
    "\n",
    "# display random 10 entries in list\n",
    "i = random.randint(0, len(keywords)-10)\n",
    "keywords[i+0:i+10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connect to MWS and create productsAPI object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load current ASINs in database "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "asins_in_db = bnn.get_asin_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loop through Keywords\n",
    "For each found product, save ASIN to one of two lists if it's not already tracked in database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword_lookup(query):\n",
    "    ''' Perform keyword lookup and return list of 10 matching ASINS, as well as:\n",
    "        Title, publication date, listprice, salesrank\n",
    "        and\n",
    "        requests remaining, time to full reset\n",
    "    '''\n",
    "    result_list = [] #will be list of tuples of product_info\n",
    "    \n",
    "    response = products_api.list_matching_products(marketplace_id, query, context_id)\n",
    "    \n",
    "    # Get info about requests reamining\n",
    "    #requests_max = response.headers['x-mws-quota-max']\n",
    "    requests_remaining = response.headers['x-mws-quota-remaining']\n",
    "    reset_time = response.headers['x-mws-quota-resetsOn']\n",
    "    amztime = response.headers['X-Amz-Date'] \n",
    "    reset_time_obj = datetime.datetime.strptime(reset_time[0:19],'%Y-%m-%dT%H:%M:%S')\n",
    "    amz_time_obj = datetime.datetime.strptime(amztime,'%a, %d %b %Y %H:%M:%S %Z')\n",
    "    td = reset_time_obj - amz_time_obj\n",
    "    seconds_to_full_reset = td.total_seconds()\n",
    "    request_info = (requests_remaining,seconds_to_full_reset)\n",
    "    \n",
    "    # Get product info\n",
    "    for product in response.parsed.Products.Product: \n",
    "        asin = product.Identifiers.MarketplaceASIN.ASIN\n",
    "        title = product.AttributeSets.ItemAttributes.Title\n",
    "        \n",
    "        try: \n",
    "            pubdate = product.AttributeSets.ItemAttributes.PublicationDate\n",
    "            pubdate = datetime.datetime(int(pubdate[0:4]),int(pubdate[5:7]),int(pubdate[8:10]))\n",
    "        except: \n",
    "            pubdate = datetime.datetime.now().strftime(\"%Y-%m-%d\") #placeholder\n",
    "\n",
    "        try:\n",
    "            listprice = float(product.AttributeSets.ItemAttributes.ListPrice.Amount)\n",
    "        except: \n",
    "            listprice = 0 #placeholder\n",
    "            \n",
    "        try:\n",
    "            salesrank = int(product.SalesRankings.SalesRank[0].Rank)\n",
    "        except: \n",
    "            salesrank = 30000000 #assume book very unpopular if no listed rank\n",
    "            \n",
    "        try: \n",
    "            num_pages = int(product.AttributeSets.ItemAttributes.NumberOfPages)\n",
    "        except:\n",
    "            num_pages = 0\n",
    "            \n",
    "        product_info = {'asin': asin,\n",
    "                        'title': title,\n",
    "                        'pubdate': pubdate,\n",
    "                        'listprice': listprice,\n",
    "                        'salesrank': salesrank,\n",
    "                        'num_pages': num_pages}\n",
    "        result_list.append(product_info)\n",
    "    \n",
    "    return result_list, request_info\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Winter Sports, requests remaining: 612.0\n",
      "Windows XP, requests remaining: 612.0\n",
      "Volcanology, requests remaining: 612.0\n",
      "Unemployment, requests remaining: 612.0\n",
      "Thesauruses, requests remaining: 612.0\n",
      "Space Marine, requests remaining: 611.0\n",
      "Retailing, requests remaining: 611.0\n",
      "Remedies, requests remaining: 611.0\n",
      "Reading Skills, requests remaining: 610.0\n",
      "Punk, requests remaining: 609.0\n",
      "Psychology & Christianity, requests remaining: 608.0\n",
      "Microprocessor Design, requests remaining: 606.0\n",
      "Lacrosse, requests remaining: 604.0\n",
      "Illustration, requests remaining: 603.0\n",
      "Fiber Optics, requests remaining: 603.0\n",
      "skipped keywords:\n",
      "['Winter Sports', 'Windows XP', 'Volcanology', 'Unemployment', 'Thesauruses', 'Space Marine', 'Retailing', 'Remedies', 'Reading Skills', 'Punk', 'Psychology & Christianity', 'Microprocessor Design', 'Lacrosse', 'Illustration', 'Fiber Optics']\n"
     ]
    }
   ],
   "source": [
    "'''def get_ASINs_from_keywords():\n",
    "    return\n",
    "'''\n",
    "#print('Expect the queries to take at least '+ str(len(keywords)/720) + ' hours')\n",
    "\n",
    "#new_asins_df = pd.DataFrame(columns=[])\n",
    "#skipped_keywords = []\n",
    "i=0\n",
    "for query in keywords:\n",
    "#for query in skipped_keywords:\n",
    "    time.sleep(5+(random.randint(0,10)/10)) #sleep between 5 and 6sec to limit rate (refreshes 1 token/5sec)\n",
    "    try: \n",
    "        (result_list, request_info) = keyword_lookup(query)\n",
    "        print(query + ', requests remaining: ' + str(request_info[0]))\n",
    "        new_asins_df = new_asins_df.append(result_list,ignore_index=True)\n",
    "    except: #hit the request limit - wait until next available time and restart\n",
    "        print('timeout of ' + str(request_info[1]) + ' seconds')\n",
    "        time.sleep(request_info[1]) # put in sleep time here\n",
    "        skipped_keywords.append(query)\n",
    "    i+=1\n",
    "    if i==50:\n",
    "        # save data to csv in case of interruption\n",
    "        new_asins_df.to_csv('./asin_lists/asins_from_keywords_'+date+'.csv',index=False,sep='\\t')\n",
    "        i=0\n",
    "\n",
    "print('skipped keywords:')\n",
    "print(skipped_keywords)\n",
    "# Go back and run through skipped keywords as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lynx/anaconda3/envs/booksnn/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# Final save\n",
    "new_asins_df.to_csv('./asin_lists/asins_from_keywords_'+date+'.csv',index=False,sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Check criteria for interesting products\n",
    "Save separate list of only interesting ASINs with some details. \n",
    "\n",
    "Criteria:\n",
    "* At least 6mo since pub date. (Why? New items have messed up salesrank, see below. Also need enough history for valid analysis.) (Consider also removing very old books)\n",
    "* List price > $25\n",
    "* Sales rank < 2M\n",
    "* num_pages > 0\n",
    "* Not already in local database\n",
    "\n",
    "Note - shitty listings are missing many parameters, e.g. [this one](https://www.amazon.com/ZOROASTRIANISM-History-Hoshang-J-Khambatta/dp/0926592270/). \n",
    "\n",
    "Observation - books that are very new (days, weeks) have an unusually low sales rank because salesrank is adjusted to age. E.g. 1 sale in first month of book's publication is pretty pathetic, but it seems to have comparable salesrank to a book that sells one copy weekly, consistently over time. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ASINs found: 27634\n",
      "Number of them that are interesting: 9785\n"
     ]
    }
   ],
   "source": [
    "#check listprice and salesrank\n",
    "interesting_df = new_asins_df[(new_asins_df['listprice'] > 25) & (new_asins_df['salesrank'] < 2000000)]\n",
    "#check older than 6mo\n",
    "interesting_df = interesting_df[interesting_df['pubdate'] < datetime.datetime.now()-datetime.timedelta(days = 180)]\n",
    "\n",
    "#check not in existing list\n",
    "#interesting_df = interesting_df[~interesting_df['asin'].isin(asins_in_db)]\n",
    "\n",
    "print('Number of ASINs found: ' + str(len(new_asins_df)))\n",
    "print('Number of them that are interesting: ' + str(len(interesting_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save interesting list to tab-delimited file\n",
    "Remember to use tab separator because commas in titles mess things up. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lynx/anaconda3/envs/booksnn/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "interesting_df.to_csv('./asin_lists/asins_from_keywords_interesting_'+date+'.csv',index=False,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
